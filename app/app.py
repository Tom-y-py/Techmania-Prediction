"""
FastAPI backend pro predikci n√°v≈°tƒõvnosti Techmanie.
"""

from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
from datetime import date, datetime
import pandas as pd
import numpy as np
import joblib
import sys
import os
from pathlib import Path
from dotenv import load_dotenv
from sqlalchemy.orm import Session

# Naƒç√≠st promƒõnn√© prost≈ôed√≠
load_dotenv()

# Import datab√°zov√Ωch komponent
try:
    from database import (
        get_db, init_db, Prediction, HistoricalData, TemplateData,
        get_next_version, validate_future_date, mark_template_complete,
        get_complete_template_records, get_latest_prediction
    )
    DATABASE_ENABLED = True
except ImportError as e:
    print(f"‚ö†Ô∏è Database module not available: {e}")
    DATABASE_ENABLED = False

# P≈ôidat src do path
sys.path.append(str(Path(__file__).parent.parent / 'src'))

from feature_engineering import create_features
from services import holiday_service, weather_service

# Konfigurace z .env
ENVIRONMENT = os.getenv('ENVIRONMENT', 'development')
HOST = os.getenv('HOST', '0.0.0.0')
PORT = int(os.getenv('PORT', '5000'))
CORS_ORIGINS = os.getenv('CORS_ORIGINS', 'http://localhost:3000').split(',')
API_TITLE = os.getenv('API_TITLE', 'Techmania Prediction API')
API_VERSION = os.getenv('API_VERSION', '2.0.0')
DEBUG = os.getenv('DEBUG', 'true').lower() == 'true'

# Nastaven√≠ cest podle prost≈ôed√≠
if ENVIRONMENT == 'production':
    # Cesty v Docker kontejneru
    BASE_DIR = Path('/app')
    MODELS_DIR = BASE_DIR / 'models'
    DATA_DIR = BASE_DIR / 'data' / 'raw'
else:
    # Lok√°ln√≠ cesty pro development
    BASE_DIR = Path(__file__).parent.parent
    MODELS_DIR = BASE_DIR / 'models'
    DATA_DIR = BASE_DIR / 'data' / 'raw'

print(f"üîß Prost≈ôed√≠: {ENVIRONMENT}")
print(f"üìÅ Adres√°≈ô model≈Ø: {MODELS_DIR}")
print(f"üìÅ Adres√°≈ô dat: {DATA_DIR}")

# Inicializace FastAPI
app = FastAPI(
    title=API_TITLE,
    description="API pro predikci n√°v≈°tƒõvnosti Techmanie pomoc√≠ ensemble modelu",
    version=API_VERSION,
    debug=DEBUG
)

# CORS middleware s konfigurac√≠ podle prost≈ôed√≠
app.add_middleware(
    CORSMiddleware,
    allow_origins=[origin.strip() for origin in CORS_ORIGINS],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Glob√°ln√≠ promƒõnn√© pro modely
models = {}
feature_columns = None
ensemble_weights = None
ensemble_info = None  # Nov√°: informace o typu ensemble (weighted/stacking/single_lgb)
meta_model = None  # Nov√°: meta-model pro stacking
historical_data = None  # Pro ukl√°d√°n√≠ historick√Ωch dat

# Pydantic modely pro request/response
class PredictionRequest(BaseModel):
    date: str = Field(..., description="Datum ve form√°tu YYYY-MM-DD", example="2026-01-15")
    is_holiday: Optional[bool] = Field(None, description="Je sv√°tek? (None = auto-detekce)")
    opening_hours: Optional[str] = Field("9-17", description="Otev√≠rac√≠ doba")

class WeatherInfo(BaseModel):
    temperature_mean: float
    precipitation: float
    weather_description: str
    is_nice_weather: bool

class HolidayInfo(BaseModel):
    is_holiday: bool
    holiday_name: Optional[str]

class PredictionResponse(BaseModel):
    date: str
    predicted_visitors: int
    confidence_interval: Dict[str, int]
    model_info: Dict[str, Any]
    holiday_info: HolidayInfo
    weather_info: WeatherInfo

class RangePredictionRequest(BaseModel):
    start_date: str = Field(..., description="Poƒç√°teƒçn√≠ datum", example="2026-01-01")
    end_date: str = Field(..., description="Koneƒçn√© datum", example="2026-01-31")

class DayPrediction(BaseModel):
    date: str
    predicted_visitors: int
    confidence_interval: Dict[str, int]
    holiday_info: HolidayInfo
    weather_info: WeatherInfo
    day_of_week: str
    is_weekend: bool

class RangePredictionResponse(BaseModel):
    predictions: List[DayPrediction]
    total_predicted: int
    average_daily: float
    period_days: int

class HealthResponse(BaseModel):
    status: str
    models_loaded: Dict[str, bool]
    features_count: Optional[int]

class StatsResponse(BaseModel):
    total_visitors: int
    avg_daily_visitors: float
    peak_day: str
    peak_visitors: int
    trend: float
    data_start_date: str
    data_end_date: str

class HistoricalDataPoint(BaseModel):
    date: str
    visitors: int

class HistoricalDataResponse(BaseModel):
    data: List[HistoricalDataPoint]
    start_date: str
    end_date: str
    total_days: int

class PredictionVersion(BaseModel):
    version: int
    predicted_visitors: int
    created_at: str
    model_name: str
    temperature_mean: Optional[float]
    precipitation: Optional[float]
    is_nice_weather: Optional[int]
    notes: Optional[str]

class PredictionHistoryResponse(BaseModel):
    date: str
    versions: List[PredictionVersion]
    total_versions: int

# Nov√© modely pro PATCH endpoint
class TemplateDataUpdate(BaseModel):
    """Data pro aktualizaci template z√°znamu s re√°ln√Ωmi hodnotami"""
    date: str = Field(..., description="Datum ve form√°tu YYYY-MM-DD", example="2026-01-15")
    total_visitors: Optional[int] = Field(None, description="Celkov√Ω poƒçet n√°v≈°tƒõvn√≠k≈Ø")
    school_visitors: Optional[int] = Field(None, description="Poƒçet ≈°koln√≠ch n√°v≈°tƒõvn√≠k≈Ø")
    public_visitors: Optional[int] = Field(None, description="Poƒçet ve≈ôejn√Ωch n√°v≈°tƒõvn√≠k≈Ø")
    extra: Optional[str] = Field(None, description="Extra pozn√°mky")
    opening_hours: Optional[str] = Field(None, description="Otev√≠rac√≠ doba")

class TemplateDataPatchResponse(BaseModel):
    """Odpovƒõƒè z PATCH endpointu"""
    success: bool
    message: str
    date: str
    was_complete: bool
    is_complete: bool
    updated_fields: List[str]

class TemplateDataBatchUpdate(BaseModel):
    """Batch aktualizace v√≠ce template z√°znam≈Ø najednou"""
    updates: List[TemplateDataUpdate] = Field(..., description="Seznam aktualizac√≠")

class TemplateDataBatchResponse(BaseModel):
    """Odpovƒõƒè z batch update"""
    success: bool
    total_processed: int
    successful_updates: int
    failed_updates: int
    details: List[TemplateDataPatchResponse]

# Naƒçten√≠ model≈Ø p≈ôi startu
@app.on_event("startup")
async def load_models():
    """Naƒçte v≈°echny natr√©novan√© modely a historick√° data."""
    global models, feature_columns, ensemble_weights, ensemble_info, meta_model, historical_data
    
    # Inicializovat datab√°zi pokud je dostupn√°
    if DATABASE_ENABLED:
        try:
            init_db()
            print("‚úÖ Database initialized")
        except Exception as e:
            print(f"‚ö†Ô∏è Database initialization failed: {e}")
    
    try:
        # Naƒçten√≠ jednotliv√Ωch model≈Ø
        models['lightgbm'] = joblib.load(MODELS_DIR / 'lightgbm_model.pkl')
        models['xgboost'] = joblib.load(MODELS_DIR / 'xgboost_model.pkl')
        models['catboost'] = joblib.load(MODELS_DIR / 'catboost_model.pkl')
        
        # Naƒçten√≠ vah ensemble
        ensemble_weights = joblib.load(MODELS_DIR / 'ensemble_weights.pkl')
        
        # Naƒçten√≠ informace o typu ensemble (nov√© modely)
        ensemble_info_path = MODELS_DIR / 'ensemble_info.pkl'
        if ensemble_info_path.exists():
            ensemble_info = joblib.load(ensemble_info_path)
            print(f"   - Ensemble type: {ensemble_info.get('type', 'weighted').upper()}")
            print(f"   - Ensemble MAE: {ensemble_info.get('mae', 'N/A')}")
            
            # Naƒç√≠st meta-model pokud je stacking
            if ensemble_info.get('type') == 'stacking':
                meta_model_path = MODELS_DIR / 'meta_model.pkl'
                if meta_model_path.exists():
                    meta_model = joblib.load(meta_model_path)
                    print(f"   - Meta-model loaded: ‚úÖ")
                else:
                    print(f"   ‚ö†Ô∏è Meta-model not found, falling back to weighted")
                    ensemble_info['type'] = 'weighted'
        else:
            # Star≈°√≠ modely bez ensemble_info = weighted
            ensemble_info = {'type': 'weighted', 'mae': None}
            print(f"   - Ensemble type: WEIGHTED (legacy)")
        
        # Naƒçten√≠ seznamu features
        feature_columns = joblib.load(MODELS_DIR / 'feature_columns.pkl')
        
        # Naƒçten√≠ historick√Ωch dat pro statistiky
        try:
            # 1. Naƒç√≠st historick√° data (do 2025)
            historical_data = pd.read_csv(DATA_DIR / 'techmania_cleaned_master.csv')
            historical_data['date'] = pd.to_datetime(historical_data['date'])
            print(f"   - Historick√° data: {len(historical_data)} z√°znam≈Ø (do {historical_data['date'].max().date()})")
            
            # 2. Naƒç√≠st template pro 2026 (s p≈ôedvyplnƒõn√Ωmi holiday features)
            template_2026_path = DATA_DIR / 'techmania_2026_template.csv'
            if template_2026_path.exists():
                df_2026 = pd.read_csv(template_2026_path)
                df_2026['date'] = pd.to_datetime(df_2026['date'])
                
                # Spojit s historick√Ωmi daty (pokud u≈æ tam nejsou data z 2026)
                max_historical_date = historical_data['date'].max()
                df_2026_filtered = df_2026[df_2026['date'] > max_historical_date]
                
                if len(df_2026_filtered) > 0:
                    # Filtrovat jen ≈ô√°dky s n√°v≈°tƒõvnost√≠ (pro statistiky)
                    # Pro predikce pou≈æijeme i ≈ô√°dky bez n√°v≈°tƒõvnosti
                    historical_data = pd.concat([historical_data, df_2026_filtered], ignore_index=True)
                    print(f"   - 2026 template: {len(df_2026_filtered)} ≈ô√°dk≈Ø (holiday features p≈ôedvyplnƒõny)")
            else:
                print(f"   ‚ö†Ô∏è 2026 template nenalezen: {template_2026_path}")
        except Exception as e:
            print(f"   ‚ö†Ô∏è Historick√° data nenaƒçtena: {e}")
            historical_data = None
        
        print("‚úÖ V≈°echny modely √∫spƒõ≈°nƒõ naƒçteny")
        print(f"   - LightGBM: naƒçten")
        print(f"   - XGBoost: naƒçten")
        print(f"   - CatBoost: naƒçten")
        print(f"   - Features: {len(feature_columns)} sloupc≈Ø")
        print(f"   - Ensemble weights: {ensemble_weights}")
        
    except Exception as e:
        print(f"‚ùå Chyba p≈ôi naƒç√≠t√°n√≠ model≈Ø: {e}")
        raise

def make_ensemble_prediction(df: pd.DataFrame) -> np.ndarray:
    """
    Provede ensemble predikci podle typu ensemble.
    Podporuje: weighted, stacking, single_lgb
    """
    import xgboost as xgb
    
    # Predikce z ka≈æd√©ho modelu
    lgb_pred = models['lightgbm'].predict(df[feature_columns])
    
    # XGBoost pot≈ôebuje DMatrix
    dmatrix = xgb.DMatrix(df[feature_columns])
    xgb_pred = models['xgboost'].predict(dmatrix)
    
    cat_pred = models['catboost'].predict(df[feature_columns])
    
    # Rozhodnout podle typu ensemble
    ensemble_type = ensemble_info.get('type', 'weighted') if ensemble_info else 'weighted'
    
    if ensemble_type == 'single_lgb':
        # SINGLE: Pou≈æ√≠t pouze LightGBM
        ensemble_pred = lgb_pred
        print(f"   üéØ Using SINGLE LightGBM model")
        
    elif ensemble_type == 'stacking' and meta_model is not None:
        # STACKING: Pou≈æ√≠t meta-model
        meta_features = np.column_stack([lgb_pred, xgb_pred, cat_pred])
        ensemble_pred = meta_model.predict(meta_features)
        print(f"   üß† Using STACKING ensemble with meta-model")
        
    else:
        # WEIGHTED: V√°≈æen√Ω pr≈Ømƒõr (default)
        ensemble_pred = (
            ensemble_weights[0] * lgb_pred +
            ensemble_weights[1] * xgb_pred +
            ensemble_weights[2] * cat_pred
        )
        print(f"   ‚öñÔ∏è Using WEIGHTED ensemble (weights: {ensemble_weights})")
    
    return ensemble_pred

# API Endpointy
@app.get("/", tags=["Info"])
async def root():
    """Root endpoint - informace o API."""
    return {
        "name": "Techmania Prediction API",
        "version": "2.0.0",
        "message": "FastAPI backend pro predikci n√°v≈°tƒõvnosti Techmanie",
        "docs": "/docs",
        "endpoints": {
            "/": "Tento endpoint",
            "/docs": "Interaktivn√≠ dokumentace (Swagger UI)",
            "/redoc": "Alternativn√≠ dokumentace (ReDoc)",
            "/health": "GET - Health check",
            "/predict": "POST - Predikce pro konkr√©tn√≠ datum",
            "/predict/range": "POST - Predikce pro obdob√≠",
            "/models/info": "GET - Informace o modelech"
        }
    }


@app.get("/health", response_model=HealthResponse, tags=["Info"])
async def health_check():
    """Health check endpoint."""
    return {
        "status": "healthy",
        "models_loaded": {
            "lightgbm": "lightgbm" in models,
            "xgboost": "xgboost" in models,
            "catboost": "catboost" in models,
        },
        "features_count": len(feature_columns) if feature_columns is not None else None
    }

@app.get("/models/info", tags=["Info"])
async def models_info():
    """Informace o naƒçten√Ωch modelech."""
    if not models:
        raise HTTPException(status_code=503, detail="Modely nejsou naƒçteny")
    
    ensemble_type = ensemble_info.get('type', 'weighted') if ensemble_info else 'weighted'
    ensemble_mae = ensemble_info.get('mae') if ensemble_info else None
    
    response = {
        "models": list(models.keys()),
        "ensemble_type": ensemble_type.upper(),
        "ensemble_weights": {
            "lightgbm": float(ensemble_weights[0]),
            "xgboost": float(ensemble_weights[1]),
            "catboost": float(ensemble_weights[2])
        } if ensemble_weights is not None and len(ensemble_weights) >= 3 else None,
        "features_count": len(feature_columns) if feature_columns else 0,
        "feature_sample": feature_columns[:10] if feature_columns else []
    }
    
    if ensemble_mae is not None:
        response["validation_mae"] = float(ensemble_mae)
    
    if ensemble_type == 'stacking':
        response["meta_model"] = "Ridge Regression" if meta_model is not None else "Not loaded"
    
    return response

@app.get("/stats", response_model=StatsResponse, tags=["Statistics"])
async def get_statistics():
    """
    Z√≠sk√° statistiky z historick√Ωch dat.
    """
    if historical_data is None:
        raise HTTPException(status_code=503, detail="Historick√° data nejsou dostupn√°")
    
    try:
        # Odfiltrovat NaN hodnoty
        clean_data = historical_data.dropna(subset=['total_visitors'])
        
        if len(clean_data) == 0:
            raise HTTPException(status_code=503, detail="≈Ω√°dn√° platn√° data nejsou k dispozici")
        
        # V√Ωpoƒçet statistik
        total_visitors = int(clean_data['total_visitors'].sum())
        avg_daily = float(clean_data['total_visitors'].mean())
        
        # Naj√≠t den s nejvy≈°≈°√≠ n√°v≈°tƒõvnost√≠
        peak_idx = clean_data['total_visitors'].idxmax()
        peak_day = clean_data.loc[peak_idx, 'date'].strftime('%d. %B %Y')
        peak_visitors = int(clean_data.loc[peak_idx, 'total_visitors'])
        
        # Vypoƒç√≠tat trend (posledn√≠ mƒõs√≠c vs p≈ôedchoz√≠ mƒõs√≠c)
        last_month = clean_data.tail(30)
        prev_month = clean_data.iloc[-60:-30] if len(clean_data) >= 60 else clean_data.head(30)
        
        if len(prev_month) > 0 and prev_month['total_visitors'].mean() > 0:
            trend = ((last_month['total_visitors'].mean() - prev_month['total_visitors'].mean()) / 
                    prev_month['total_visitors'].mean() * 100)
            trend = float(trend) if not np.isnan(trend) else 0.0
        else:
            trend = 0.0
        
        return {
            "total_visitors": total_visitors,
            "avg_daily_visitors": avg_daily,
            "peak_day": peak_day,
            "peak_visitors": peak_visitors,
            "trend": round(trend, 1),
            "data_start_date": clean_data['date'].min().strftime('%Y-%m-%d'),
            "data_end_date": clean_data['date'].max().strftime('%Y-%m-%d')
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Chyba p≈ôi v√Ωpoƒçtu statistik: {str(e)}")

@app.get("/historical", response_model=HistoricalDataResponse, tags=["Statistics"])
async def get_historical_data(days: int = 30):
    """
    Z√≠sk√° historick√° data za posledn√≠ N dn√≠.
    """
    if historical_data is None:
        raise HTTPException(status_code=503, detail="Historick√° data nejsou dostupn√°")
    
    try:
        # Odfiltrovat NaN hodnoty
        clean_data = historical_data.dropna(subset=['total_visitors'])
        
        if len(clean_data) == 0:
            raise HTTPException(status_code=503, detail="≈Ω√°dn√° platn√° data nejsou k dispozici")
        
        # Z√≠skat posledn√≠ N dn√≠
        recent_data = clean_data.tail(days).copy()
        
        data_points = []
        for _, row in recent_data.iterrows():
            visitors = row['total_visitors']
            # Dal≈°√≠ kontrola pro jistotu
            if pd.notna(visitors):
                data_points.append({
                    "date": row['date'].strftime('%Y-%m-%d'),
                    "visitors": int(visitors)
                })
        
        if len(data_points) == 0:
            raise HTTPException(status_code=503, detail="≈Ω√°dn√° platn√° data pro zadan√© obdob√≠")
        
        return {
            "data": data_points,
            "start_date": recent_data['date'].min().strftime('%Y-%m-%d'),
            "end_date": recent_data['date'].max().strftime('%Y-%m-%d'),
            "total_days": len(data_points)
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Chyba p≈ôi naƒç√≠t√°n√≠ dat: {str(e)}")

@app.post("/predict", response_model=PredictionResponse, tags=["Predictions"])
async def predict(request: PredictionRequest, db: Session = Depends(get_db) if DATABASE_ENABLED else None):
    """
    Predikce n√°v≈°tƒõvnosti pro konkr√©tn√≠ datum.
    
    Pou≈æije ensemble model (LightGBM + XGBoost + CatBoost) pro predikci.
    Automaticky detekuje sv√°tky a z√≠sk√°v√° informace o poƒças√≠.
    Ulo≈æ√≠ predikci do datab√°ze s verzov√°n√≠m.
    
    D≈ÆLE≈ΩIT√â: Nep≈ôij√≠m√° predikce do minulosti (pouze budouc√≠ data).
    """
    if not models:
        raise HTTPException(status_code=503, detail="Modely nejsou naƒçteny")
    
    try:
        # Parsov√°n√≠ data
        pred_date = pd.to_datetime(request.date).date()
        
        # ========== VALIDACE: ZAK√ÅZAT PREDIKCE DO MINULOSTI ==========
        if DATABASE_ENABLED and not validate_future_date(pred_date):
            today = date.today()
            raise HTTPException(
                status_code=400,
                detail=f"Nelze vytvo≈ôit predikci do minulosti. Po≈æadovan√© datum: {pred_date}, Dne≈°n√≠ datum: {today}. "
                       f"Predikce jsou povoleny pouze pro budouc√≠ data."
            )
        
        # Zkusit naj√≠t datum v historick√Ωch datech (m≈Ø≈æe obsahovat p≈ôedvyplnƒõn√© holiday features)
        existing_row = None
        if historical_data is not None:
            existing_row_df = historical_data[historical_data['date'] == pd.to_datetime(pred_date)]
            if not existing_row_df.empty:
                existing_row = existing_row_df.iloc[0].to_dict()
                print(f"   ‚ÑπÔ∏è Datum {pred_date} nalezeno v datech (pou≈æiji p≈ôedvyplnƒõn√© holiday features)")
        
        # Auto-detekce sv√°tku (pokud nen√≠ zad√°n A nen√≠ v datech)
        if request.is_holiday is None:
            if existing_row and 'is_holiday' in existing_row:
                # Pou≈æ√≠t hodnotu z CSV
                is_holiday = bool(existing_row['is_holiday'])
                holiday_name = existing_row.get('extra') if pd.notna(existing_row.get('extra')) else None
                print(f"   ‚úì Holiday info z CSV: is_holiday={is_holiday}")
            else:
                # Fallback na holiday_service
                holiday_info = holiday_service.get_holiday_info(pred_date)
                is_holiday = holiday_info['is_holiday']
                holiday_name = holiday_info['holiday_name']
                print(f"   ‚úì Holiday info z holiday_service: is_holiday={is_holiday}")
        else:
            is_holiday = request.is_holiday
            holiday_name = None if not is_holiday else "U≈æivatelem zadan√Ω sv√°tek"
        
        # Z√≠skat informace o poƒças√≠
        weather_data = weather_service.get_weather(pred_date)
        
        # Zkontrolovat, ≈æe m√°me v≈°echna pot≈ôebn√° data o poƒças√≠
        required_weather_fields = ['temperature_max', 'temperature_min', 'temperature_mean', 'precipitation']
        missing_fields = [field for field in required_weather_fields if field not in weather_data or weather_data[field] is None]
        
        if missing_fields:
            raise HTTPException(
                status_code=503,
                detail=f"Weather data incomplete: missing fields {missing_fields}. Cannot make prediction without real weather data."
            )
        
        # Vytvo≈ôen√≠ DataFrame pro predikci
        # Pokud m√°me existuj√≠c√≠ ≈ô√°dek z CSV, pou≈æijeme ho jako z√°klad
        if existing_row:
            # Pou≈æ√≠t existuj√≠c√≠ ≈ô√°dek a p≈ôepsat jen weather data a opening_hours
            df_pred = pd.DataFrame([existing_row])
            df_pred['date'] = pd.to_datetime(df_pred['date'])
            
            # Aktualizovat weather data z API
            for k, v in weather_data.items():
                df_pred[k] = v
            
            # Aktualizovat opening_hours
            df_pred['opening_hours'] = request.opening_hours
            
            print(f"   ‚úì Pou≈æity p≈ôedvyplnƒõn√© holiday features z CSV")
        else:
            # Vytvo≈ôit nov√Ω ≈ô√°dek (fallback pro data mimo 2026 template)
            df_pred = pd.DataFrame({
                'date': [pd.to_datetime(pred_date)],
                'total_visitors': [np.nan],  # NaN = nezn√°m√° hodnota (predikce)
                'school_visitors': [np.nan],
                'public_visitors': [np.nan],
                'extra': [holiday_name],
                'opening_hours': [request.opening_hours],
                # V≈°echna weather data z API (rozbal√≠me dictionary)
                **{k: [v] for k, v in weather_data.items()}
            })
            print(f"   ‚ö†Ô∏è Datum nenalezeno v CSV, vytv√°≈ô√≠m nov√Ω ≈ô√°dek")
        
        # create_features p≈ôid√° ƒçasov√© features, ≈°koln√≠ pr√°zdniny, odvozen√© features atd.
        df_pred = create_features(df_pred)
        
        # Vybrat pouze features, kter√© model oƒçek√°v√°
        available_features = [col for col in feature_columns if col in df_pred.columns]
        X_pred = df_pred[available_features].copy()
        
        # Doplnit chybƒõj√≠c√≠ features (nap≈ô. nƒõkter√© weather features mohou chybƒõt)
        missing_features = [col for col in feature_columns if col not in df_pred.columns]
        if missing_features:
            print(f"   ‚ö†Ô∏è Warning: Missing features: {missing_features[:10]}{'...' if len(missing_features) > 10 else ''}")
            # Dopln√≠me nulami nebo medi√°ny
            for col in missing_features:
                X_pred[col] = 0
        
        # Nahradit NaN hodnotami nulou
        X_pred = X_pred.fillna(0)
        
        # Ujistit se, ≈æe m√°me spr√°vn√© po≈ôad√≠ sloupc≈Ø
        X_pred = X_pred[feature_columns]
        
        # Ensemble predikce
        prediction = make_ensemble_prediction(X_pred)[0]
        
        # Zaokrouhlen√≠ na cel√© ƒç√≠slo
        prediction = int(np.round(prediction))
        
        # Ulo≈æit predikci do datab√°ze s verzov√°n√≠m
        if DATABASE_ENABLED and db is not None:
            try:
                # Z√≠skat dal≈°√≠ verzi
                version = get_next_version(db, pred_date)
                
                # Z√≠skat den v t√Ωdnu v ƒçe≈°tinƒõ
                day_names = ['pondƒõl√≠', '√∫ter√Ω', 'st≈ôeda', 'ƒçtvrtek', 'p√°tek', 'sobota', 'nedƒõle']
                day_of_week_cz = day_names[pred_date.weekday()]
                
                # Vytvo≈ôit nov√Ω z√°znam predikce
                db_prediction = Prediction(
                    prediction_date=pred_date,
                    predicted_visitors=prediction,
                    temperature_mean=weather_data.get('temperature_mean'),
                    precipitation=weather_data.get('precipitation'),
                    wind_speed_max=weather_data.get('wind_speed_max'),
                    is_rainy=1 if weather_data.get('is_rainy', False) else 0,
                    is_snowy=1 if weather_data.get('is_snowy', False) else 0,
                    is_nice_weather=1 if weather_data.get('is_nice_weather', False) else 0,
                    day_of_week=day_of_week_cz,
                    is_weekend=1 if pred_date.weekday() >= 5 else 0,
                    is_holiday=1 if is_holiday else 0,
                    model_name="ensemble",
                    confidence_lower=int(prediction * 0.85),
                    confidence_upper=int(prediction * 1.15),
                    version=version,
                    created_by="api"
                )
                db.add(db_prediction)
                db.commit()
                print(f"‚úÖ Prediction saved to database: {pred_date} (version {version})")
            except Exception as e:
                print(f"‚ö†Ô∏è Failed to save prediction to database: {e}")
                db.rollback()
        
        return {
            "date": pred_date.strftime('%Y-%m-%d'),
            "predicted_visitors": prediction,
            "confidence_interval": {
                "lower": int(prediction * 0.85),
                "upper": int(prediction * 1.15)
            },
            "model_info": {
                "type": ensemble_info.get('type', 'weighted').upper() if ensemble_info else "WEIGHTED",
                "models": list(models.keys()),
                "weights": {
                    "lightgbm": float(ensemble_weights[0]),
                    "xgboost": float(ensemble_weights[1]),
                    "catboost": float(ensemble_weights[2])
                } if ensemble_weights is not None and len(ensemble_weights) >= 3 else None
            },
            "holiday_info": {
                "is_holiday": is_holiday,
                "holiday_name": holiday_name
            },
            "weather_info": {
                "temperature_mean": float(weather_data['temperature_mean']),
                "precipitation": float(weather_data['precipitation']),
                "weather_description": weather_data.get('weather_description', 'N/A'),
                "is_nice_weather": bool(weather_data.get('is_nice_weather', False))
            }
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Chyba p≈ôi predikci: {str(e)}")

@app.post("/predict/range", response_model=RangePredictionResponse, tags=["Predictions"])
async def predict_range(request: RangePredictionRequest):
    """
    Predikce n√°v≈°tƒõvnosti pro ƒçasov√© obdob√≠.
    
    Vytvo≈ô√≠ predikce pro ka≈æd√Ω den v zadan√©m obdob√≠.
    Automaticky stahuje weather data pro ka≈æd√Ω den z Open-Meteo API.
    
    D≈ÆLE≈ΩIT√â: Nep≈ôij√≠m√° predikce do minulosti (pouze budouc√≠ data).
    """
    if not models:
        raise HTTPException(status_code=503, detail="Modely nejsou naƒçteny")
    
    try:
        from predict import predict_date_range
        
        start_date = pd.to_datetime(request.start_date)
        end_date = pd.to_datetime(request.end_date)
        
        if start_date > end_date:
            raise HTTPException(status_code=400, detail="start_date mus√≠ b√Ωt p≈ôed end_date")
        
        # ========== VALIDACE: ZAK√ÅZAT PREDIKCE DO MINULOSTI ==========
        if DATABASE_ENABLED:
            today = date.today()
            if start_date.date() <= today:
                raise HTTPException(
                    status_code=400,
                    detail=f"Nelze vytvo≈ôit predikci do minulosti. Start datum: {start_date.date()}, Dne≈°n√≠ datum: {today}. "
                           f"Predikce jsou povoleny pouze pro budouc√≠ data. Pou≈æijte start_date > {today}."
                )
        
        # Pou≈æ√≠t funkci z predict.py kter√° automaticky stahuje weather data
        models_dict = {
            'lgb': models['lightgbm'],
            'xgb': models['xgboost'],
            'cat': models['catboost'],
            'weights': ensemble_weights,
            'feature_cols': feature_columns,
            'ensemble_type': ensemble_info.get('type', 'weighted') if ensemble_info else 'weighted',
            'meta_model': meta_model
        }
        
        results_df = predict_date_range(start_date, end_date, models_dict)
        
        # Form√°tov√°n√≠ v√Ωstupu s detailn√≠mi informacemi
        predictions = []
        for _, row in results_df.iterrows():
            pred_date = row['date'].date()
            prediction_value = int(row['prediction'])
            
            # Z√≠skat informace o sv√°tku
            holiday_info_data = holiday_service.get_holiday_info(pred_date)
            
            # Z√≠skat informace o poƒças√≠
            weather_data = weather_service.get_weather(pred_date)
            
            # Den v t√Ωdnu
            day_name = row['date'].strftime('%A')
            day_name_cs = {
                'Monday': 'Pondƒõl√≠',
                'Tuesday': '√öter√Ω',
                'Wednesday': 'St≈ôeda',
                'Thursday': 'ƒåtvrtek',
                'Friday': 'P√°tek',
                'Saturday': 'Sobota',
                'Sunday': 'Nedƒõle'
            }.get(day_name, day_name)
            
            predictions.append({
                "date": row['date'].strftime('%Y-%m-%d'),
                "predicted_visitors": prediction_value,
                "confidence_interval": {
                    "lower": int(prediction_value * 0.85),
                    "upper": int(prediction_value * 1.15)
                },
                "holiday_info": {
                    "is_holiday": holiday_info_data['is_holiday'],
                    "holiday_name": holiday_info_data['holiday_name']
                },
                "weather_info": {
                    "temperature_mean": float(weather_data['temperature_mean']),
                    "precipitation": float(weather_data['precipitation']),
                    "weather_description": weather_data.get('weather_description', 'N/A'),
                    "is_nice_weather": bool(weather_data.get('is_nice_weather', False))
                },
                "day_of_week": day_name_cs,
                "is_weekend": row['date'].dayofweek >= 5
            })
        
        total = int(results_df['prediction'].sum())
        
        return {
            "predictions": predictions,
            "total_predicted": total,
            "average_daily": float(results_df['prediction'].mean()),
            "period_days": len(results_df)
        }
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        print(f"‚ùå Error in predict_range: {e}")
        print(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Chyba p≈ôi predikci: {str(e)}")

@app.get("/predictions/history/{date_str}", response_model=PredictionHistoryResponse, tags=["Predictions"])
async def get_prediction_history(date_str: str, db: Session = Depends(get_db) if DATABASE_ENABLED else None):
    """
    Z√≠sk√° v≈°echny verze predikce pro dan√© datum.
    
    Umo≈æ≈àuje vidƒõt, jak se predikce mƒõnila v ƒçase.
    """
    if not DATABASE_ENABLED or db is None:
        raise HTTPException(status_code=503, detail="Database nen√≠ dostupn√°")
    
    try:
        pred_date = pd.to_datetime(date_str).date()
        
        # Naƒç√≠st v≈°echny verze predikce pro toto datum
        predictions = db.query(Prediction)\
            .filter(Prediction.prediction_date == pred_date)\
            .order_by(Prediction.version.desc())\
            .all()
        
        if not predictions:
            raise HTTPException(status_code=404, detail=f"≈Ω√°dn√© predikce pro datum {date_str}")
        
        versions = []
        for pred in predictions:
            versions.append({
                "version": pred.version,
                "predicted_visitors": pred.predicted_visitors,
                "created_at": pred.created_at.isoformat(),
                "model_name": pred.model_name,
                "temperature_mean": pred.temperature_mean,
                "precipitation": pred.precipitation,
                "is_nice_weather": pred.is_nice_weather,
                "notes": pred.notes
            })
        
        return {
            "date": date_str,
            "versions": versions,
            "total_versions": len(versions)
        }
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Chyba p≈ôi naƒç√≠t√°n√≠ historie: {str(e)}")

@app.get("/predictions/latest", tags=["Predictions"])
async def get_latest_predictions(limit: int = 20, db: Session = Depends(get_db) if DATABASE_ENABLED else None):
    """
    Z√≠sk√° nejnovƒõj≈°√≠ predikce (posledn√≠ verze pro ka≈æd√© datum).
    """
    if not DATABASE_ENABLED or db is None:
        raise HTTPException(status_code=503, detail="Database nen√≠ dostupn√°")
    
    try:
        from sqlalchemy import func
        
        # Z√≠skat nejnovƒõj≈°√≠ verzi pro ka≈æd√© datum
        subquery = db.query(
            Prediction.prediction_date,
            func.max(Prediction.version).label('max_version')
        ).group_by(Prediction.prediction_date).subquery()
        
        predictions = db.query(Prediction)\
            .join(
                subquery,
                (Prediction.prediction_date == subquery.c.prediction_date) &
                (Prediction.version == subquery.c.max_version)
            )\
            .order_by(Prediction.created_at.desc())\
            .limit(limit)\
            .all()
        
        results = []
        for pred in predictions:
            results.append({
                "date": pred.prediction_date.isoformat(),
                "predicted_visitors": pred.predicted_visitors,
                "version": pred.version,
                "created_at": pred.created_at.isoformat(),
                "model_name": pred.model_name,
                "temperature_mean": pred.temperature_mean,
                "precipitation": pred.precipitation,
                "is_nice_weather": pred.is_nice_weather,
                "confidence_interval": {
                    "lower": pred.confidence_lower,
                    "upper": pred.confidence_upper
                }
            })
        
        return {
            "predictions": results,
            "count": len(results)
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Chyba p≈ôi naƒç√≠t√°n√≠ predikc√≠: {str(e)}")

@app.get("/data/historical", tags=["Data"])
async def get_historical_from_db(
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    limit: int = 100,
    db: Session = Depends(get_db) if DATABASE_ENABLED else None
):
    """
    Z√≠sk√° historick√° data z datab√°ze.
    
    Pokud nen√≠ datab√°ze dostupn√°, pou≈æije se fallback na CSV.
    """
    if DATABASE_ENABLED and db is not None:
        try:
            query = db.query(HistoricalData)
            
            if start_date:
                start = pd.to_datetime(start_date).date()
                query = query.filter(HistoricalData.date >= start)
            
            if end_date:
                end = pd.to_datetime(end_date).date()
                query = query.filter(HistoricalData.date <= end)
            
            records = query.order_by(HistoricalData.date.desc()).limit(limit).all()
            
            results = []
            for record in records:
                results.append({
                    "date": record.date.isoformat(),
                    "visitors": record.total_visitors,
                    "school_visitors": record.school_visitors,
                    "public_visitors": record.public_visitors,
                    "day_of_week": record.day_of_week,
                    "temperature_mean": record.temperature_mean,
                    "precipitation": record.precipitation,
                    "is_weekend": record.is_weekend,
                    "is_holiday": record.is_holiday,
                    "is_nice_weather": record.is_nice_weather
                })
            
            return {
                "source": "database",
                "data": results,
                "count": len(results)
            }
        except Exception as e:
            print(f"‚ö†Ô∏è Database query failed: {e}")
            # Fallback na CSV
    
    # Fallback pokud datab√°ze nen√≠ dostupn√°
    if historical_data is not None:
        df = historical_data.copy()
        
        if start_date:
            df = df[df['date'] >= pd.to_datetime(start_date)]
        if end_date:
            df = df[df['date'] <= pd.to_datetime(end_date)]
        
        df = df.tail(limit)
        
        results = []
        for _, row in df.iterrows():
            results.append({
                "date": row['date'].strftime('%Y-%m-%d'),
                "visitors": int(row['total_visitors'])
            })
        
        return {
            "source": "csv",
            "data": results,
            "count": len(results)
        }
    
    raise HTTPException(status_code=503, detail="Historick√° data nejsou dostupn√°")


# ========== NOV√â ENDPOINTY PRO TEMPLATE DATA A PATCH ==========

@app.patch("/template/update", response_model=TemplateDataPatchResponse, tags=["Template"])
async def update_template_record(
    update_data: TemplateDataUpdate,
    db: Session = Depends(get_db)
):
    """
    PATCH endpoint pro aktualizaci template z√°znamu s re√°ln√Ωmi daty.
    
    Kdy≈æ Techmania p≈ôid√° re√°ln√° data do Excelu (nap≈ô. n√°v≈°tƒõvnost pro 1.1.2026),
    tento endpoint detekuje zmƒõnu, aktualizuje z√°znam v DB a nastav√≠ flag is_complete=True.
    
    Kompletn√≠ z√°znamy se pak mohou pou≈æ√≠t pro grafy a statistiky.
    """
    if not DATABASE_ENABLED:
        raise HTTPException(status_code=503, detail="Database not available")
    
    try:
        # Parse date
        record_date = pd.to_datetime(update_data.date).date()
        
        # Find template record
        template_record = db.query(TemplateData)\
            .filter(TemplateData.date == record_date)\
            .first()
        
        if not template_record:
            raise HTTPException(
                status_code=404,
                detail=f"Template z√°znam pro datum {update_data.date} nebyl nalezen"
            )
        
        # Track what was updated
        was_complete = template_record.is_complete
        updated_fields = []
        
        # Update visitor data if provided
        if update_data.total_visitors is not None:
            template_record.total_visitors = update_data.total_visitors
            updated_fields.append("total_visitors")
        
        if update_data.school_visitors is not None:
            template_record.school_visitors = update_data.school_visitors
            updated_fields.append("school_visitors")
        
        if update_data.public_visitors is not None:
            template_record.public_visitors = update_data.public_visitors
            updated_fields.append("public_visitors")
        
        if update_data.extra is not None:
            template_record.extra = update_data.extra
            updated_fields.append("extra")
        
        if update_data.opening_hours is not None:
            template_record.opening_hours = update_data.opening_hours
            updated_fields.append("opening_hours")
        
        # If total_visitors was added, mark as complete
        if update_data.total_visitors is not None and not was_complete:
            template_record.is_complete = True
            template_record.completed_at = datetime.utcnow()
            updated_fields.append("is_complete")
        
        template_record.updated_at = datetime.utcnow()
        db.commit()
        
        return TemplateDataPatchResponse(
            success=True,
            message=f"Z√°znam pro {update_data.date} byl √∫spƒõ≈°nƒõ aktualizov√°n" + 
                   (" a oznaƒçen jako kompletn√≠" if not was_complete and template_record.is_complete else ""),
            date=update_data.date,
            was_complete=was_complete,
            is_complete=template_record.is_complete,
            updated_fields=updated_fields
        )
        
    except HTTPException:
        raise
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=f"Chyba p≈ôi aktualizaci: {str(e)}")


@app.patch("/template/batch-update", response_model=TemplateDataBatchResponse, tags=["Template"])
async def batch_update_template_records(
    batch_data: TemplateDataBatchUpdate,
    db: Session = Depends(get_db)
):
    """
    Batch PATCH endpoint pro aktualizaci v√≠ce template z√°znam≈Ø najednou.
    
    Umo≈æ≈àuje nahr√°t cel√Ω Excel soubor s v√≠ce dny najednou.
    """
    if not DATABASE_ENABLED:
        raise HTTPException(status_code=503, detail="Database not available")
    
    results = []
    successful = 0
    failed = 0
    
    for update_data in batch_data.updates:
        try:
            # Parse date
            record_date = pd.to_datetime(update_data.date).date()
            
            # Find template record
            template_record = db.query(TemplateData)\
                .filter(TemplateData.date == record_date)\
                .first()
            
            if not template_record:
                results.append(TemplateDataPatchResponse(
                    success=False,
                    message=f"Z√°znam pro {update_data.date} nebyl nalezen",
                    date=update_data.date,
                    was_complete=False,
                    is_complete=False,
                    updated_fields=[]
                ))
                failed += 1
                continue
            
            # Track changes
            was_complete = template_record.is_complete
            updated_fields = []
            
            # Update fields
            if update_data.total_visitors is not None:
                template_record.total_visitors = update_data.total_visitors
                updated_fields.append("total_visitors")
            
            if update_data.school_visitors is not None:
                template_record.school_visitors = update_data.school_visitors
                updated_fields.append("school_visitors")
            
            if update_data.public_visitors is not None:
                template_record.public_visitors = update_data.public_visitors
                updated_fields.append("public_visitors")
            
            if update_data.extra is not None:
                template_record.extra = update_data.extra
                updated_fields.append("extra")
            
            if update_data.opening_hours is not None:
                template_record.opening_hours = update_data.opening_hours
                updated_fields.append("opening_hours")
            
            # Mark as complete if total_visitors was added
            if update_data.total_visitors is not None and not was_complete:
                template_record.is_complete = True
                template_record.completed_at = datetime.utcnow()
                updated_fields.append("is_complete")
            
            template_record.updated_at = datetime.utcnow()
            
            results.append(TemplateDataPatchResponse(
                success=True,
                message=f"√öspƒõ≈°nƒõ aktualizov√°no",
                date=update_data.date,
                was_complete=was_complete,
                is_complete=template_record.is_complete,
                updated_fields=updated_fields
            ))
            successful += 1
            
        except Exception as e:
            results.append(TemplateDataPatchResponse(
                success=False,
                message=f"Chyba: {str(e)}",
                date=update_data.date,
                was_complete=False,
                is_complete=False,
                updated_fields=[]
            ))
            failed += 1
    
    # Commit all changes at once
    try:
        db.commit()
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=f"Chyba p≈ôi ukl√°d√°n√≠: {str(e)}")
    
    return TemplateDataBatchResponse(
        success=successful > 0,
        total_processed=len(batch_data.updates),
        successful_updates=successful,
        failed_updates=failed,
        details=results
    )


@app.get("/template/status", tags=["Template"])
async def get_template_status(
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    complete_only: bool = False,
    db: Session = Depends(get_db)
):
    """
    Z√≠sk√° status template z√°znam≈Ø - kter√© maj√≠ kompletn√≠ data a kter√© ne.
    
    Args:
        start_date: Filtr od data (YYYY-MM-DD)
        end_date: Filtr do data (YYYY-MM-DD)
        complete_only: Vr√°tit pouze kompletn√≠ z√°znamy
    """
    if not DATABASE_ENABLED:
        raise HTTPException(status_code=503, detail="Database not available")
    
    try:
        query = db.query(TemplateData)
        
        if start_date:
            start = pd.to_datetime(start_date).date()
            query = query.filter(TemplateData.date >= start)
        
        if end_date:
            end = pd.to_datetime(end_date).date()
            query = query.filter(TemplateData.date <= end)
        
        if complete_only:
            query = query.filter(TemplateData.is_complete == True)
        
        records = query.order_by(TemplateData.date).all()
        
        results = []
        for record in records:
            results.append({
                "date": record.date.isoformat(),
                "is_complete": record.is_complete,
                "completed_at": record.completed_at.isoformat() if record.completed_at else None,
                "total_visitors": record.total_visitors,
                "has_visitor_data": record.total_visitors is not None,
                "day_of_week": record.day_of_week,
                "is_weekend": record.is_weekend,
                "is_holiday": record.is_holiday
            })
        
        complete_count = sum(1 for r in results if r["is_complete"])
        
        return {
            "total_records": len(results),
            "complete_records": complete_count,
            "incomplete_records": len(results) - complete_count,
            "data": results
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Chyba p≈ôi naƒç√≠t√°n√≠ statusu: {str(e)}")


@app.get("/template/complete", tags=["Template"])
async def get_complete_template_data(
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    db: Session = Depends(get_db)
):
    """
    Z√≠sk√° v≈°echny kompletn√≠ template z√°znamy (s re√°ln√Ωmi daty).
    Tyto z√°znamy se mohou pou≈æ√≠t pro grafy a statistiky.
    """
    if not DATABASE_ENABLED:
        raise HTTPException(status_code=503, detail="Database not available")
    
    try:
        start = pd.to_datetime(start_date).date() if start_date else None
        end = pd.to_datetime(end_date).date() if end_date else None
        
        records = get_complete_template_records(db, start, end)
        
        results = []
        for record in records:
            results.append({
                "date": record.date.isoformat(),
                "total_visitors": record.total_visitors,
                "school_visitors": record.school_visitors,
                "public_visitors": record.public_visitors,
                "day_of_week": record.day_of_week,
                "temperature_mean": record.temperature_mean,
                "precipitation": record.precipitation,
                "is_weekend": record.is_weekend,
                "is_holiday": record.is_holiday,
                "is_nice_weather": record.is_nice_weather,
                "completed_at": record.completed_at.isoformat() if record.completed_at else None
            })
        
        return {
            "source": "template_data",
            "complete_records": len(results),
            "data": results
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Chyba p≈ôi naƒç√≠t√°n√≠ dat: {str(e)}")


if __name__ == '__main__':
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

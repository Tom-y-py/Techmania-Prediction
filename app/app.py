"""
FastAPI backend pro predikci nÃ¡vÅ¡tÄ›vnosti Techmanie.
"""

from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
from datetime import date, datetime
import pandas as pd
import numpy as np
import joblib
import sys
import os
from pathlib import Path
from dotenv import load_dotenv
from sqlalchemy.orm import Session

# NaÄÃ­st promÄ›nnÃ© prostÅ™edÃ­
load_dotenv()

# Import databÃ¡zovÃ½ch komponent
try:
    from database import get_db, init_db, Prediction, HistoricalData, get_next_version
    DATABASE_ENABLED = True
except ImportError as e:
    print(f"âš ï¸ Database module not available: {e}")
    DATABASE_ENABLED = False

# PÅ™idat src do path
sys.path.append(str(Path(__file__).parent.parent / 'src'))

from feature_engineering import create_features
from services import holiday_service, weather_service

# Konfigurace z .env
ENVIRONMENT = os.getenv('ENVIRONMENT', 'development')
HOST = os.getenv('HOST', '0.0.0.0')
PORT = int(os.getenv('PORT', '5000'))
CORS_ORIGINS = os.getenv('CORS_ORIGINS', 'http://localhost:3000').split(',')
API_TITLE = os.getenv('API_TITLE', 'Techmania Prediction API')
API_VERSION = os.getenv('API_VERSION', '2.0.0')
DEBUG = os.getenv('DEBUG', 'true').lower() == 'true'

# NastavenÃ­ cest podle prostÅ™edÃ­
if ENVIRONMENT == 'production':
    # Cesty v Docker kontejneru
    BASE_DIR = Path('/app')
    MODELS_DIR = BASE_DIR / 'models'
    DATA_DIR = BASE_DIR / 'data' / 'raw'
else:
    # LokÃ¡lnÃ­ cesty pro development
    BASE_DIR = Path(__file__).parent.parent
    MODELS_DIR = BASE_DIR / 'models'
    DATA_DIR = BASE_DIR / 'data' / 'raw'

print(f"ðŸ”§ ProstÅ™edÃ­: {ENVIRONMENT}")
print(f"ðŸ“ AdresÃ¡Å™ modelÅ¯: {MODELS_DIR}")
print(f"ðŸ“ AdresÃ¡Å™ dat: {DATA_DIR}")

# Inicializace FastAPI
app = FastAPI(
    title=API_TITLE,
    description="API pro predikci nÃ¡vÅ¡tÄ›vnosti Techmanie pomocÃ­ ensemble modelu",
    version=API_VERSION,
    debug=DEBUG
)

# CORS middleware s konfiguracÃ­ podle prostÅ™edÃ­
app.add_middleware(
    CORSMiddleware,
    allow_origins=[origin.strip() for origin in CORS_ORIGINS],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# GlobÃ¡lnÃ­ promÄ›nnÃ© pro modely
models = {}
feature_columns = None
ensemble_weights = None
ensemble_info = None  # NovÃ¡: informace o typu ensemble (weighted/stacking/single_lgb)
meta_model = None  # NovÃ¡: meta-model pro stacking
historical_data = None  # Pro uklÃ¡dÃ¡nÃ­ historickÃ½ch dat

# Pydantic modely pro request/response
class PredictionRequest(BaseModel):
    date: str = Field(..., description="Datum ve formÃ¡tu YYYY-MM-DD", example="2026-01-15")
    is_holiday: Optional[bool] = Field(None, description="Je svÃ¡tek? (None = auto-detekce)")
    opening_hours: Optional[str] = Field("9-17", description="OtevÃ­racÃ­ doba")

class WeatherInfo(BaseModel):
    temperature_mean: float
    precipitation: float
    weather_description: str
    is_nice_weather: bool

class HolidayInfo(BaseModel):
    is_holiday: bool
    holiday_name: Optional[str]

class PredictionResponse(BaseModel):
    date: str
    predicted_visitors: int
    confidence_interval: Dict[str, int]
    model_info: Dict[str, Any]
    holiday_info: HolidayInfo
    weather_info: WeatherInfo

class RangePredictionRequest(BaseModel):
    start_date: str = Field(..., description="PoÄÃ¡teÄnÃ­ datum", example="2026-01-01")
    end_date: str = Field(..., description="KoneÄnÃ© datum", example="2026-01-31")

class DayPrediction(BaseModel):
    date: str
    predicted_visitors: int
    confidence_interval: Dict[str, int]
    holiday_info: HolidayInfo
    weather_info: WeatherInfo
    day_of_week: str
    is_weekend: bool

class RangePredictionResponse(BaseModel):
    predictions: List[DayPrediction]
    total_predicted: int
    average_daily: float
    period_days: int

class HealthResponse(BaseModel):
    status: str
    models_loaded: Dict[str, bool]
    features_count: Optional[int]

class StatsResponse(BaseModel):
    total_visitors: int
    avg_daily_visitors: float
    peak_day: str
    peak_visitors: int
    trend: float
    data_start_date: str
    data_end_date: str

class HistoricalDataPoint(BaseModel):
    date: str
    visitors: int

class HistoricalDataResponse(BaseModel):
    data: List[HistoricalDataPoint]
    start_date: str
    end_date: str
    total_days: int

class PredictionVersion(BaseModel):
    version: int
    predicted_visitors: int
    created_at: str
    model_name: str
    temperature_mean: Optional[float]
    precipitation: Optional[float]
    is_nice_weather: Optional[int]
    notes: Optional[str]

class PredictionHistoryResponse(BaseModel):
    date: str
    versions: List[PredictionVersion]
    total_versions: int

# NaÄtenÃ­ modelÅ¯ pÅ™i startu
@app.on_event("startup")
async def load_models():
    """NaÄte vÅ¡echny natrÃ©novanÃ© modely a historickÃ¡ data."""
    global models, feature_columns, ensemble_weights, ensemble_info, meta_model, historical_data
    
    # Inicializovat databÃ¡zi pokud je dostupnÃ¡
    if DATABASE_ENABLED:
        try:
            init_db()
            print("âœ… Database initialized")
        except Exception as e:
            print(f"âš ï¸ Database initialization failed: {e}")
    
    try:
        # NaÄtenÃ­ jednotlivÃ½ch modelÅ¯
        models['lightgbm'] = joblib.load(MODELS_DIR / 'lightgbm_model.pkl')
        models['xgboost'] = joblib.load(MODELS_DIR / 'xgboost_model.pkl')
        models['catboost'] = joblib.load(MODELS_DIR / 'catboost_model.pkl')
        
        # NaÄtenÃ­ vah ensemble
        ensemble_weights = joblib.load(MODELS_DIR / 'ensemble_weights.pkl')
        
        # NaÄtenÃ­ informace o typu ensemble (novÃ© modely)
        ensemble_info_path = MODELS_DIR / 'ensemble_info.pkl'
        if ensemble_info_path.exists():
            ensemble_info = joblib.load(ensemble_info_path)
            print(f"   - Ensemble type: {ensemble_info.get('type', 'weighted').upper()}")
            print(f"   - Ensemble MAE: {ensemble_info.get('mae', 'N/A')}")
            
            # NaÄÃ­st meta-model pokud je stacking
            if ensemble_info.get('type') == 'stacking':
                meta_model_path = MODELS_DIR / 'meta_model.pkl'
                if meta_model_path.exists():
                    meta_model = joblib.load(meta_model_path)
                    print(f"   - Meta-model loaded: âœ…")
                else:
                    print(f"   âš ï¸ Meta-model not found, falling back to weighted")
                    ensemble_info['type'] = 'weighted'
        else:
            # StarÅ¡Ã­ modely bez ensemble_info = weighted
            ensemble_info = {'type': 'weighted', 'mae': None}
            print(f"   - Ensemble type: WEIGHTED (legacy)")
        
        # NaÄtenÃ­ seznamu features
        feature_columns = joblib.load(MODELS_DIR / 'feature_columns.pkl')
        
        # NaÄtenÃ­ historickÃ½ch dat pro statistiky
        try:
            # 1. NaÄÃ­st historickÃ¡ data (do 2025)
            historical_data = pd.read_csv(DATA_DIR / 'techmania_cleaned_master.csv')
            historical_data['date'] = pd.to_datetime(historical_data['date'])
            print(f"   - HistorickÃ¡ data: {len(historical_data)} zÃ¡znamÅ¯ (do {historical_data['date'].max().date()})")
            
            # 2. NaÄÃ­st template pro 2026 (s pÅ™edvyplnÄ›nÃ½mi holiday features)
            template_2026_path = DATA_DIR / 'techmania_2026_template.csv'
            if template_2026_path.exists():
                df_2026 = pd.read_csv(template_2026_path)
                df_2026['date'] = pd.to_datetime(df_2026['date'])
                
                # Spojit s historickÃ½mi daty (pokud uÅ¾ tam nejsou data z 2026)
                max_historical_date = historical_data['date'].max()
                df_2026_filtered = df_2026[df_2026['date'] > max_historical_date]
                
                if len(df_2026_filtered) > 0:
                    # Filtrovat jen Å™Ã¡dky s nÃ¡vÅ¡tÄ›vnostÃ­ (pro statistiky)
                    # Pro predikce pouÅ¾ijeme i Å™Ã¡dky bez nÃ¡vÅ¡tÄ›vnosti
                    historical_data = pd.concat([historical_data, df_2026_filtered], ignore_index=True)
                    print(f"   - 2026 template: {len(df_2026_filtered)} Å™Ã¡dkÅ¯ (holiday features pÅ™edvyplnÄ›ny)")
            else:
                print(f"   âš ï¸ 2026 template nenalezen: {template_2026_path}")
        except Exception as e:
            print(f"   âš ï¸ HistorickÃ¡ data nenaÄtena: {e}")
            historical_data = None
        
        print("âœ… VÅ¡echny modely ÃºspÄ›Å¡nÄ› naÄteny")
        print(f"   - LightGBM: naÄten")
        print(f"   - XGBoost: naÄten")
        print(f"   - CatBoost: naÄten")
        print(f"   - Features: {len(feature_columns)} sloupcÅ¯")
        print(f"   - Ensemble weights: {ensemble_weights}")
        
    except Exception as e:
        print(f"âŒ Chyba pÅ™i naÄÃ­tÃ¡nÃ­ modelÅ¯: {e}")
        raise

def make_ensemble_prediction(df: pd.DataFrame) -> np.ndarray:
    """
    Provede ensemble predikci podle typu ensemble.
    Podporuje: weighted, stacking, single_lgb
    """
    import xgboost as xgb
    
    # Predikce z kaÅ¾dÃ©ho modelu
    lgb_pred = models['lightgbm'].predict(df[feature_columns])
    
    # XGBoost potÅ™ebuje DMatrix
    dmatrix = xgb.DMatrix(df[feature_columns])
    xgb_pred = models['xgboost'].predict(dmatrix)
    
    cat_pred = models['catboost'].predict(df[feature_columns])
    
    # Rozhodnout podle typu ensemble
    ensemble_type = ensemble_info.get('type', 'weighted') if ensemble_info else 'weighted'
    
    if ensemble_type == 'single_lgb':
        # SINGLE: PouÅ¾Ã­t pouze LightGBM
        ensemble_pred = lgb_pred
        print(f"   ðŸŽ¯ Using SINGLE LightGBM model")
        
    elif ensemble_type == 'stacking' and meta_model is not None:
        # STACKING: PouÅ¾Ã­t meta-model
        meta_features = np.column_stack([lgb_pred, xgb_pred, cat_pred])
        ensemble_pred = meta_model.predict(meta_features)
        print(f"   ðŸ§  Using STACKING ensemble with meta-model")
        
    else:
        # WEIGHTED: VÃ¡Å¾enÃ½ prÅ¯mÄ›r (default)
        ensemble_pred = (
            ensemble_weights[0] * lgb_pred +
            ensemble_weights[1] * xgb_pred +
            ensemble_weights[2] * cat_pred
        )
        print(f"   âš–ï¸ Using WEIGHTED ensemble (weights: {ensemble_weights})")
    
    return ensemble_pred

# API Endpointy
@app.get("/", tags=["Info"])
async def root():
    """Root endpoint - informace o API."""
    return {
        "name": "Techmania Prediction API",
        "version": "2.0.0",
        "message": "FastAPI backend pro predikci nÃ¡vÅ¡tÄ›vnosti Techmanie",
        "docs": "/docs",
        "endpoints": {
            "/": "Tento endpoint",
            "/docs": "InteraktivnÃ­ dokumentace (Swagger UI)",
            "/redoc": "AlternativnÃ­ dokumentace (ReDoc)",
            "/health": "GET - Health check",
            "/predict": "POST - Predikce pro konkrÃ©tnÃ­ datum",
            "/predict/range": "POST - Predikce pro obdobÃ­",
            "/models/info": "GET - Informace o modelech"
        }
    }


@app.get("/health", response_model=HealthResponse, tags=["Info"])
async def health_check():
    """Health check endpoint."""
    return {
        "status": "healthy",
        "models_loaded": {
            "lightgbm": "lightgbm" in models,
            "xgboost": "xgboost" in models,
            "catboost": "catboost" in models,
        },
        "features_count": len(feature_columns) if feature_columns is not None else None
    }

@app.get("/models/info", tags=["Info"])
async def models_info():
    """Informace o naÄtenÃ½ch modelech."""
    if not models:
        raise HTTPException(status_code=503, detail="Modely nejsou naÄteny")
    
    ensemble_type = ensemble_info.get('type', 'weighted') if ensemble_info else 'weighted'
    ensemble_mae = ensemble_info.get('mae') if ensemble_info else None
    
    response = {
        "models": list(models.keys()),
        "ensemble_type": ensemble_type.upper(),
        "ensemble_weights": {
            "lightgbm": float(ensemble_weights[0]),
            "xgboost": float(ensemble_weights[1]),
            "catboost": float(ensemble_weights[2])
        } if ensemble_weights is not None and len(ensemble_weights) >= 3 else None,
        "features_count": len(feature_columns) if feature_columns else 0,
        "feature_sample": feature_columns[:10] if feature_columns else []
    }
    
    if ensemble_mae is not None:
        response["validation_mae"] = float(ensemble_mae)
    
    if ensemble_type == 'stacking':
        response["meta_model"] = "Ridge Regression" if meta_model is not None else "Not loaded"
    
    return response

@app.get("/stats", response_model=StatsResponse, tags=["Statistics"])
async def get_statistics():
    """
    ZÃ­skÃ¡ statistiky z historickÃ½ch dat.
    """
    if historical_data is None:
        raise HTTPException(status_code=503, detail="HistorickÃ¡ data nejsou dostupnÃ¡")
    
    try:
        # VÃ½poÄet statistik
        total_visitors = int(historical_data['total_visitors'].sum())
        avg_daily = float(historical_data['total_visitors'].mean())
        
        # NajÃ­t den s nejvyÅ¡Å¡Ã­ nÃ¡vÅ¡tÄ›vnostÃ­
        peak_idx = historical_data['total_visitors'].idxmax()
        peak_day = historical_data.loc[peak_idx, 'date'].strftime('%d. %B %Y')
        peak_visitors = int(historical_data.loc[peak_idx, 'total_visitors'])
        
        # VypoÄÃ­tat trend (poslednÃ­ mÄ›sÃ­c vs pÅ™edchozÃ­ mÄ›sÃ­c)
        last_month = historical_data.tail(30)
        prev_month = historical_data.iloc[-60:-30] if len(historical_data) >= 60 else historical_data.head(30)
        
        if len(prev_month) > 0:
            trend = ((last_month['total_visitors'].mean() - prev_month['total_visitors'].mean()) / 
                    prev_month['total_visitors'].mean() * 100)
        else:
            trend = 0.0
        
        return {
            "total_visitors": total_visitors,
            "avg_daily_visitors": avg_daily,
            "peak_day": peak_day,
            "peak_visitors": peak_visitors,
            "trend": round(trend, 1),
            "data_start_date": historical_data['date'].min().strftime('%Y-%m-%d'),
            "data_end_date": historical_data['date'].max().strftime('%Y-%m-%d')
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Chyba pÅ™i vÃ½poÄtu statistik: {str(e)}")

@app.get("/historical", response_model=HistoricalDataResponse, tags=["Statistics"])
async def get_historical_data(days: int = 30):
    """
    ZÃ­skÃ¡ historickÃ¡ data za poslednÃ­ N dnÃ­.
    """
    if historical_data is None:
        raise HTTPException(status_code=503, detail="HistorickÃ¡ data nejsou dostupnÃ¡")
    
    try:
        # ZÃ­skat poslednÃ­ N dnÃ­
        recent_data = historical_data.tail(days).copy()
        
        data_points = []
        for _, row in recent_data.iterrows():
            data_points.append({
                "date": row['date'].strftime('%Y-%m-%d'),
                "visitors": int(row['total_visitors'])
            })
        
        return {
            "data": data_points,
            "start_date": recent_data['date'].min().strftime('%Y-%m-%d'),
            "end_date": recent_data['date'].max().strftime('%Y-%m-%d'),
            "total_days": len(data_points)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Chyba pÅ™i naÄÃ­tÃ¡nÃ­ dat: {str(e)}")

@app.post("/predict", response_model=PredictionResponse, tags=["Predictions"])
async def predict(request: PredictionRequest, db: Session = Depends(get_db) if DATABASE_ENABLED else None):
    """
    Predikce nÃ¡vÅ¡tÄ›vnosti pro konkrÃ©tnÃ­ datum.
    
    PouÅ¾ije ensemble model (LightGBM + XGBoost + CatBoost) pro predikci.
    Automaticky detekuje svÃ¡tky a zÃ­skÃ¡vÃ¡ informace o poÄasÃ­.
    UloÅ¾Ã­ predikci do databÃ¡ze s verzovÃ¡nÃ­m.
    """
    if not models:
        raise HTTPException(status_code=503, detail="Modely nejsou naÄteny")
    
    try:
        # ParsovÃ¡nÃ­ data
        pred_date = pd.to_datetime(request.date).date()
        
        # Zkusit najÃ­t datum v historickÃ½ch datech (mÅ¯Å¾e obsahovat pÅ™edvyplnÄ›nÃ© holiday features)
        existing_row = None
        if historical_data is not None:
            existing_row_df = historical_data[historical_data['date'] == pd.to_datetime(pred_date)]
            if not existing_row_df.empty:
                existing_row = existing_row_df.iloc[0].to_dict()
                print(f"   â„¹ï¸ Datum {pred_date} nalezeno v datech (pouÅ¾iji pÅ™edvyplnÄ›nÃ© holiday features)")
        
        # Auto-detekce svÃ¡tku (pokud nenÃ­ zadÃ¡n A nenÃ­ v datech)
        if request.is_holiday is None:
            if existing_row and 'is_holiday' in existing_row:
                # PouÅ¾Ã­t hodnotu z CSV
                is_holiday = bool(existing_row['is_holiday'])
                holiday_name = existing_row.get('extra') if pd.notna(existing_row.get('extra')) else None
                print(f"   âœ“ Holiday info z CSV: is_holiday={is_holiday}")
            else:
                # Fallback na holiday_service
                holiday_info = holiday_service.get_holiday_info(pred_date)
                is_holiday = holiday_info['is_holiday']
                holiday_name = holiday_info['holiday_name']
                print(f"   âœ“ Holiday info z holiday_service: is_holiday={is_holiday}")
        else:
            is_holiday = request.is_holiday
            holiday_name = None if not is_holiday else "UÅ¾ivatelem zadanÃ½ svÃ¡tek"
        
        # ZÃ­skat informace o poÄasÃ­
        weather_data = weather_service.get_weather(pred_date)
        
        # Zkontrolovat, Å¾e mÃ¡me vÅ¡echna potÅ™ebnÃ¡ data o poÄasÃ­
        required_weather_fields = ['temperature_max', 'temperature_min', 'temperature_mean', 'precipitation']
        missing_fields = [field for field in required_weather_fields if field not in weather_data or weather_data[field] is None]
        
        if missing_fields:
            raise HTTPException(
                status_code=503,
                detail=f"Weather data incomplete: missing fields {missing_fields}. Cannot make prediction without real weather data."
            )
        
        # VytvoÅ™enÃ­ DataFrame pro predikci
        # Pokud mÃ¡me existujÃ­cÃ­ Å™Ã¡dek z CSV, pouÅ¾ijeme ho jako zÃ¡klad
        if existing_row:
            # PouÅ¾Ã­t existujÃ­cÃ­ Å™Ã¡dek a pÅ™epsat jen weather data a opening_hours
            df_pred = pd.DataFrame([existing_row])
            df_pred['date'] = pd.to_datetime(df_pred['date'])
            
            # Aktualizovat weather data z API
            for k, v in weather_data.items():
                df_pred[k] = v
            
            # Aktualizovat opening_hours
            df_pred['opening_hours'] = request.opening_hours
            
            print(f"   âœ“ PouÅ¾ity pÅ™edvyplnÄ›nÃ© holiday features z CSV")
        else:
            # VytvoÅ™it novÃ½ Å™Ã¡dek (fallback pro data mimo 2026 template)
            df_pred = pd.DataFrame({
                'date': [pd.to_datetime(pred_date)],
                'total_visitors': [np.nan],  # NaN = neznÃ¡mÃ¡ hodnota (predikce)
                'school_visitors': [np.nan],
                'public_visitors': [np.nan],
                'extra': [holiday_name],
                'opening_hours': [request.opening_hours],
                # VÅ¡echna weather data z API (rozbalÃ­me dictionary)
                **{k: [v] for k, v in weather_data.items()}
            })
            print(f"   âš ï¸ Datum nenalezeno v CSV, vytvÃ¡Å™Ã­m novÃ½ Å™Ã¡dek")
        
        # create_features pÅ™idÃ¡ ÄasovÃ© features, Å¡kolnÃ­ prÃ¡zdniny, odvozenÃ© features atd.
        df_pred = create_features(df_pred)
        
        # Vybrat pouze features, kterÃ© model oÄekÃ¡vÃ¡
        available_features = [col for col in feature_columns if col in df_pred.columns]
        X_pred = df_pred[available_features].copy()
        
        # Doplnit chybÄ›jÃ­cÃ­ features (napÅ™. nÄ›kterÃ© weather features mohou chybÄ›t)
        missing_features = [col for col in feature_columns if col not in df_pred.columns]
        if missing_features:
            print(f"   âš ï¸ Warning: Missing features: {missing_features[:10]}{'...' if len(missing_features) > 10 else ''}")
            # DoplnÃ­me nulami nebo mediÃ¡ny
            for col in missing_features:
                X_pred[col] = 0
        
        # Nahradit NaN hodnotami nulou
        X_pred = X_pred.fillna(0)
        
        # Ujistit se, Å¾e mÃ¡me sprÃ¡vnÃ© poÅ™adÃ­ sloupcÅ¯
        X_pred = X_pred[feature_columns]
        
        # Ensemble predikce
        prediction = make_ensemble_prediction(X_pred)[0]
        
        # ZaokrouhlenÃ­ na celÃ© ÄÃ­slo
        prediction = int(np.round(prediction))
        
        # UloÅ¾it predikci do databÃ¡ze s verzovÃ¡nÃ­m
        if DATABASE_ENABLED and db is not None:
            try:
                # ZÃ­skat dalÅ¡Ã­ verzi
                version = get_next_version(db, pred_date)
                
                # ZÃ­skat den v tÃ½dnu v ÄeÅ¡tinÄ›
                day_names = ['pondÄ›lÃ­', 'ÃºterÃ½', 'stÅ™eda', 'Ätvrtek', 'pÃ¡tek', 'sobota', 'nedÄ›le']
                day_of_week_cz = day_names[pred_date.weekday()]
                
                # VytvoÅ™it novÃ½ zÃ¡znam predikce
                db_prediction = Prediction(
                    prediction_date=pred_date,
                    predicted_visitors=prediction,
                    temperature_mean=weather_data.get('temperature_mean'),
                    precipitation=weather_data.get('precipitation'),
                    wind_speed_max=weather_data.get('wind_speed_max'),
                    is_rainy=1 if weather_data.get('is_rainy', False) else 0,
                    is_snowy=1 if weather_data.get('is_snowy', False) else 0,
                    is_nice_weather=1 if weather_data.get('is_nice_weather', False) else 0,
                    day_of_week=day_of_week_cz,
                    is_weekend=1 if pred_date.weekday() >= 5 else 0,
                    is_holiday=1 if is_holiday else 0,
                    model_name="ensemble",
                    confidence_lower=int(prediction * 0.85),
                    confidence_upper=int(prediction * 1.15),
                    version=version,
                    created_by="api"
                )
                db.add(db_prediction)
                db.commit()
                print(f"âœ… Prediction saved to database: {pred_date} (version {version})")
            except Exception as e:
                print(f"âš ï¸ Failed to save prediction to database: {e}")
                db.rollback()
        
        return {
            "date": pred_date.strftime('%Y-%m-%d'),
            "predicted_visitors": prediction,
            "confidence_interval": {
                "lower": int(prediction * 0.85),
                "upper": int(prediction * 1.15)
            },
            "model_info": {
                "type": ensemble_info.get('type', 'weighted').upper() if ensemble_info else "WEIGHTED",
                "models": list(models.keys()),
                "weights": {
                    "lightgbm": float(ensemble_weights[0]),
                    "xgboost": float(ensemble_weights[1]),
                    "catboost": float(ensemble_weights[2])
                } if ensemble_weights is not None and len(ensemble_weights) >= 3 else None
            },
            "holiday_info": {
                "is_holiday": is_holiday,
                "holiday_name": holiday_name
            },
            "weather_info": {
                "temperature_mean": float(weather_data['temperature_mean']),
                "precipitation": float(weather_data['precipitation']),
                "weather_description": weather_data.get('weather_description', 'N/A'),
                "is_nice_weather": bool(weather_data.get('is_nice_weather', False))
            }
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Chyba pÅ™i predikci: {str(e)}")

@app.post("/predict/range", response_model=RangePredictionResponse, tags=["Predictions"])
async def predict_range(request: RangePredictionRequest):
    """
    Predikce nÃ¡vÅ¡tÄ›vnosti pro ÄasovÃ© obdobÃ­.
    
    VytvoÅ™Ã­ predikce pro kaÅ¾dÃ½ den v zadanÃ©m obdobÃ­.
    Automaticky stahuje weather data pro kaÅ¾dÃ½ den z Open-Meteo API.
    """
    if not models:
        raise HTTPException(status_code=503, detail="Modely nejsou naÄteny")
    
    try:
        from predict import predict_date_range
        
        start_date = pd.to_datetime(request.start_date)
        end_date = pd.to_datetime(request.end_date)
        
        if start_date > end_date:
            raise HTTPException(status_code=400, detail="start_date musÃ­ bÃ½t pÅ™ed end_date")
        
        # PouÅ¾Ã­t funkci z predict.py kterÃ¡ automaticky stahuje weather data
        models_dict = {
            'lgb': models['lightgbm'],
            'xgb': models['xgboost'],
            'cat': models['catboost'],
            'weights': ensemble_weights,
            'feature_cols': feature_columns,
            'ensemble_type': ensemble_info.get('type', 'weighted') if ensemble_info else 'weighted',
            'meta_model': meta_model
        }
        
        results_df = predict_date_range(start_date, end_date, models_dict)
        
        # FormÃ¡tovÃ¡nÃ­ vÃ½stupu s detailnÃ­mi informacemi
        predictions = []
        for _, row in results_df.iterrows():
            pred_date = row['date'].date()
            prediction_value = int(row['prediction'])
            
            # ZÃ­skat informace o svÃ¡tku
            holiday_info_data = holiday_service.get_holiday_info(pred_date)
            
            # ZÃ­skat informace o poÄasÃ­
            weather_data = weather_service.get_weather(pred_date)
            
            # Den v tÃ½dnu
            day_name = row['date'].strftime('%A')
            day_name_cs = {
                'Monday': 'PondÄ›lÃ­',
                'Tuesday': 'ÃšterÃ½',
                'Wednesday': 'StÅ™eda',
                'Thursday': 'ÄŒtvrtek',
                'Friday': 'PÃ¡tek',
                'Saturday': 'Sobota',
                'Sunday': 'NedÄ›le'
            }.get(day_name, day_name)
            
            predictions.append({
                "date": row['date'].strftime('%Y-%m-%d'),
                "predicted_visitors": prediction_value,
                "confidence_interval": {
                    "lower": int(prediction_value * 0.85),
                    "upper": int(prediction_value * 1.15)
                },
                "holiday_info": {
                    "is_holiday": holiday_info_data['is_holiday'],
                    "holiday_name": holiday_info_data['holiday_name']
                },
                "weather_info": {
                    "temperature_mean": float(weather_data['temperature_mean']),
                    "precipitation": float(weather_data['precipitation']),
                    "weather_description": weather_data.get('weather_description', 'N/A'),
                    "is_nice_weather": bool(weather_data.get('is_nice_weather', False))
                },
                "day_of_week": day_name_cs,
                "is_weekend": row['date'].dayofweek >= 5
            })
        
        total = int(results_df['prediction'].sum())
        
        return {
            "predictions": predictions,
            "total_predicted": total,
            "average_daily": float(results_df['prediction'].mean()),
            "period_days": len(results_df)
        }
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        print(f"âŒ Error in predict_range: {e}")
        print(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Chyba pÅ™i predikci: {str(e)}")

@app.get("/predictions/history/{date_str}", response_model=PredictionHistoryResponse, tags=["Predictions"])
async def get_prediction_history(date_str: str, db: Session = Depends(get_db) if DATABASE_ENABLED else None):
    """
    ZÃ­skÃ¡ vÅ¡echny verze predikce pro danÃ© datum.
    
    UmoÅ¾Åˆuje vidÄ›t, jak se predikce mÄ›nila v Äase.
    """
    if not DATABASE_ENABLED or db is None:
        raise HTTPException(status_code=503, detail="Database nenÃ­ dostupnÃ¡")
    
    try:
        pred_date = pd.to_datetime(date_str).date()
        
        # NaÄÃ­st vÅ¡echny verze predikce pro toto datum
        predictions = db.query(Prediction)\
            .filter(Prediction.prediction_date == pred_date)\
            .order_by(Prediction.version.desc())\
            .all()
        
        if not predictions:
            raise HTTPException(status_code=404, detail=f"Å½Ã¡dnÃ© predikce pro datum {date_str}")
        
        versions = []
        for pred in predictions:
            versions.append({
                "version": pred.version,
                "predicted_visitors": pred.predicted_visitors,
                "created_at": pred.created_at.isoformat(),
                "model_name": pred.model_name,
                "temperature_mean": pred.temperature_mean,
                "precipitation": pred.precipitation,
                "is_nice_weather": pred.is_nice_weather,
                "notes": pred.notes
            })
        
        return {
            "date": date_str,
            "versions": versions,
            "total_versions": len(versions)
        }
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Chyba pÅ™i naÄÃ­tÃ¡nÃ­ historie: {str(e)}")

@app.get("/predictions/latest", tags=["Predictions"])
async def get_latest_predictions(limit: int = 20, db: Session = Depends(get_db) if DATABASE_ENABLED else None):
    """
    ZÃ­skÃ¡ nejnovÄ›jÅ¡Ã­ predikce (poslednÃ­ verze pro kaÅ¾dÃ© datum).
    """
    if not DATABASE_ENABLED or db is None:
        raise HTTPException(status_code=503, detail="Database nenÃ­ dostupnÃ¡")
    
    try:
        from sqlalchemy import func
        
        # ZÃ­skat nejnovÄ›jÅ¡Ã­ verzi pro kaÅ¾dÃ© datum
        subquery = db.query(
            Prediction.prediction_date,
            func.max(Prediction.version).label('max_version')
        ).group_by(Prediction.prediction_date).subquery()
        
        predictions = db.query(Prediction)\
            .join(
                subquery,
                (Prediction.prediction_date == subquery.c.prediction_date) &
                (Prediction.version == subquery.c.max_version)
            )\
            .order_by(Prediction.created_at.desc())\
            .limit(limit)\
            .all()
        
        results = []
        for pred in predictions:
            results.append({
                "date": pred.prediction_date.isoformat(),
                "predicted_visitors": pred.predicted_visitors,
                "version": pred.version,
                "created_at": pred.created_at.isoformat(),
                "model_name": pred.model_name,
                "temperature_mean": pred.temperature_mean,
                "precipitation": pred.precipitation,
                "is_nice_weather": pred.is_nice_weather,
                "confidence_interval": {
                    "lower": pred.confidence_lower,
                    "upper": pred.confidence_upper
                }
            })
        
        return {
            "predictions": results,
            "count": len(results)
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Chyba pÅ™i naÄÃ­tÃ¡nÃ­ predikcÃ­: {str(e)}")

@app.get("/data/historical", tags=["Data"])
async def get_historical_from_db(
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    limit: int = 100,
    db: Session = Depends(get_db) if DATABASE_ENABLED else None
):
    """
    ZÃ­skÃ¡ historickÃ¡ data z databÃ¡ze.
    
    Pokud nenÃ­ databÃ¡ze dostupnÃ¡, pouÅ¾ije se fallback na CSV.
    """
    if DATABASE_ENABLED and db is not None:
        try:
            query = db.query(HistoricalData)
            
            if start_date:
                start = pd.to_datetime(start_date).date()
                query = query.filter(HistoricalData.date >= start)
            
            if end_date:
                end = pd.to_datetime(end_date).date()
                query = query.filter(HistoricalData.date <= end)
            
            records = query.order_by(HistoricalData.date.desc()).limit(limit).all()
            
            results = []
            for record in records:
                results.append({
                    "date": record.date.isoformat(),
                    "visitors": record.total_visitors,
                    "school_visitors": record.school_visitors,
                    "public_visitors": record.public_visitors,
                    "day_of_week": record.day_of_week,
                    "temperature_mean": record.temperature_mean,
                    "precipitation": record.precipitation,
                    "is_weekend": record.is_weekend,
                    "is_holiday": record.is_holiday,
                    "is_nice_weather": record.is_nice_weather
                })
            
            return {
                "source": "database",
                "data": results,
                "count": len(results)
            }
        except Exception as e:
            print(f"âš ï¸ Database query failed: {e}")
            # Fallback na CSV
    
    # Fallback pokud databÃ¡ze nenÃ­ dostupnÃ¡
    if historical_data is not None:
        df = historical_data.copy()
        
        if start_date:
            df = df[df['date'] >= pd.to_datetime(start_date)]
        if end_date:
            df = df[df['date'] <= pd.to_datetime(end_date)]
        
        df = df.tail(limit)
        
        results = []
        for _, row in df.iterrows():
            results.append({
                "date": row['date'].strftime('%Y-%m-%d'),
                "visitors": int(row['total_visitors'])
            })
        
        return {
            "source": "csv",
            "data": results,
            "count": len(results)
        }
    
    raise HTTPException(status_code=503, detail="HistorickÃ¡ data nejsou dostupnÃ¡")

if __name__ == '__main__':
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
